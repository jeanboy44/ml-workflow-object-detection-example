---
marp: true
theme: default
size: 16:9
paginate: false
style: |
  section {
    /* 1. 내용을 위쪽부터 채우도록 강제 설정 (중요!) */
    display: flex;
    flex-direction: column;
    justify-content: flex-start; 

    /* 2. 제목이 들어갈 공간(150px) 확보 */
    padding-top: 150px;
    padding-left: 50px;
    padding-right: 50px;
    
    font-family: "Malgun Gothic", sans-serif;
    font-size: 24px;
    background-color: white;
  }

  h1 {
    font-size: 48px;
    color: #002060;
    margin: 0;
    border: none;
    
    /* 위치 고정 */
    position: absolute;
    top: 50px;
    left: 50px; /* 좌측 여백도 맞춰주는 것이 좋습니다 */
    width: 90%; /* 제목이 길어질 경우를 대비 */
  }

  h2 {
    font-size: 24px;
    color: #666;
    margin: 0;
    
    /* 위치 고정 */
    position: absolute;
    top: 150px;
    left: 50px;
    width: 90%;
  }
---

# 실습 순서
1. 환경 설정
1. 실습 맛보기
1. 최신 모델 테스트하기
1. 실습: 데이터 이해 → 모델 학습 → 실험관리 → 배포 → 앱 검증
---

# 환경 설정
### 1. `uv` 설치
```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```
자세한 설치 방법은 [uv 공식 설치 문서](https://docs.astral.sh/uv/getting-started/installation/)에서 확인하세요.

### 2. 의존성 설치
```bash
uv sync
```

### 3. 환경 변수 설정
```bash
DATABRICKS_HOST=
DATABRICKS_TOKEN=
```

---

# 실습 맛보기

### 실습 결과물 미리 확인하기
1. streamlit app 실행
```bash
cd apps/object_detection_demo
uv run streamlit run main.py
```
1. 모델 선택
3. 버전 선택
1. 사진 선택
1. run
---

# 최신 모델 테스트하기
- 모델 다운로드
- 실험
#### 모델 다운로드
```bash
uv run scripts/dbx_volumes.py download "/Volumes/study/object_detection/model_files/IDEA-Research" --dst-path ./artifacts
uv run scripts/dbx_volumes.py download "/Volumes/study/object_detection/model_files/facebook" --dst-path ./artifacts
uv run scripts/dbx_volumes.py download "/Volumes/study/object_detection/model_files/yolo" --dst-path ./artifacts
```
(시간이 오래 걸리는 관계로) 이후에 사용할 데이터도 같이 다운로드
```bash
uv run scripts/dbx_volumes.py download "/Volumes/study/object_detection/datasets/PCB_DATASET/" --dst-path ./data
```

---

# 최신 모델 테스트하기
#### 실험
```bash
cd experiments/test_latest_models
uv run detr_pre_trained_model.py "../../data/sample_data/dog_01.jpg" # DETR
uv run yolo_pre_trained_model.py "../../data/sample_data/dog_02.jpg" # YOLO
uv run grounddino_zero_shot_inference.py "../../data/sample_data/cat_03.jpg" "cat" # GROUND DINO
```
---

# 실습
#### 문제 정의
PCB 불량탐지 비전 모델 개발
- 목적: 결함 클래스 탐지 정확도 향상
- 적용: 제조라인 검사 자동화
- 데이터: `data/PCB_DATASET` (Pascal VOC XML)

#### 데이터 설명
- 문서: `docs/PCB_DATASET 데이터 설명.md`
- 클래스 예시: Short, Open, Mousebite, Spur, Spurious Copper

---

# 데이터 이해 (EDA)

#### 데이터 다운로드(앞에서 했으면 생략)
```bash
uv run scripts/dbx_volumes.py download "/Volumes/study/object_detection/datasets/PCB_DATASET/" --dst-path ./data
```

#### 시각화 스크립트
```bash
cd experiments/eda
uv run eda_pcb_data.py
```
#### 노트북 파일
`eda_pcb_data.ipynb`

---

# 최신 모델로 PCB 이미지 테스트하기
#### 모델 다운로드 (앞에 했으면 생략 가능)
```bash
uv run scripts/dbx_volumes.py download "/Volumes/study/object_detection/model_files/" --dst-path ./artifacts
```

#### 최신 모델로 확인
```bash
cd experiments/test_latest_models
uv run detr_pre_trained_model.py "../../data/sample_data/01_missing_hole_11.jpg" # DETR
uv run yolo_pre_trained_model.py "../../data/sample_data/04_open_circuit_16.jpg" # YOLO
uv run grounddino_zero_shot_inference.py "../../data/sample_data/01_missing_hole_11.jpg" "circle" # GROUND DINO
```
---


# YOLO 활용 학습 1
- 데이터 분할 → YOLO 포맷 변환
- Fast Run으로 파이프라인 검증

#### 데이터 분할 → YOLO 포맷 변환 
```bash
cd experiments/exp01_train_yolo
uv run split_pcb_dataset.py --base-dir ../../data/PCB_DATASET --output-dir ../../data/pcb_splits
uv run prepare_yolo_dataset.py --split-dir ../../data/pcb_splits --output-dir ../../data/pcb_yolo
```

---

# YOLO 활용 학습 1
#### Fast Run으로 파이프라인 검증
```bash
uv run train_yolo.py --data-yaml ../../data/pcb_yolo/data.yaml --model ../../artifacts/yolo/yolo26n.pt --epochs 5 --imgsz 320 --batch 2 --fraction 0.01
```

-> 파라미터를 추가하고 변경하기 어려움

---

# YOLO 활용 학습 2
- hydra를 활용한 config 관리
- From Scratch
- Transfer Learning
- hyper parameter 튜닝

#### hydra를 활용한 config 관리
```bash
uv run train_yolo_hydra.py --config-name test_config
```

#### From Scratch
```bash
uv run train_yolo_hydra.py --config-name scratch_config
```

---

# YOLO 활용 학습 2
#### Transfer Learning
```bash
uv run train_yolo_hydra.py --config-name transfer_config
```

#### hyper parameter 튜닝
```bash
uv run train_yolo_hydra.py --config-name transfer_config train.imgsz=640 train.epochs=120 train.batch=16 train.mosaic=0.2 train.lr0=0.0025 train.warmup_epochs=5
```
---

# MLflow로 실험 및 모델 관리하기
- Databricks
- Experiments: 실험 관리
- Models: 모델 관리
- Catalog: 데이터 및 모델 거버넌스 관리
- Workspace: 작업 공간

#### Databricks
mlflow는 오픈 소스 MLOps도구, databricks는 분석 플랫폼으로서 mlflow 서비스를 관리형으로 제공(mlflow는 databricks에서 개발하고 관리하는 오픈소스)
https://adb-7405619072427573.13.azuredatabricks.net/

---

# MLflow로 실험 및 모델 관리하기

#### Experiments
- 실험(run) 단위로 학습 파라미터, 메트릭, 아티팩트를 기록하고 비교할 수 있음
- 동일한 데이터셋/모델 설정에서 성능 변화를 추적하고 재현 가능
- 팀 단위로 실험 결과를 공유하고 이력 관리 가능

#### Models
- 모델 버전별로 등록/승격/롤백 등 라이프사이클을 관리할 수 있음
- 실험 결과에서 등록된 모델을 서비스/배포 대상으로 연결 가능
- 스테이지별로 승인 흐름과 접근 권한을 설정할 수 있음

---

# MLflow로 실험 및 모델 관리하기

#### Catalog
- 데이터셋/테이블/모델 메타데이터를 중앙에서 관리하고 추적 가능
- 접근 권한, 리니지, 감사 이력을 통해 거버넌스를 강화할 수 있음
- 팀/프로젝트 간 표준화된 자산 카탈로그로 재사용성을 높임

#### Workspace
- 노트북, 작업, 실험, 모델 등 모든 자산을 프로젝트 단위로 구성 가능
- 사용자/그룹 권한을 관리해 협업과 보안을 동시에 지원
- 실행 결과와 산출물을 한 곳에서 확인하고 공유할 수 있음

---

# 모델 등록하기 1: pretrained 모델

- 모델 등록하기
  1. PythonModel 정의(경우에 따라 생략가능)
  2. run 에 모델 추가
  3. 등록(run에 추가된 모델 경로를 입력값으로 활용)
- 등록된 모델을 사용해서 예측하기

#### 모델 등록하기
```bash
uv run scripts/register_yolo_model.py "yolo_pretrained" "artifacts/yolo/yolo26n.pt"
```
---

# 모델 등록하기 1: pretrained 모델

#### 등록된 모델을 사용해서 예측하기
```bash
uv run scripts/predict_with_registered_model.py "yolo_pretrained" "data/sample_data/cat_01.jpg"
```

---

# 모델 등록하기 2: 학습된 모델
- run에서 모델 다운로드하기
  1. [실험](https://adb-7405619072427573.13.azuredatabricks.net/ml/experiments?o=7405619072427573)에서 내 run 정보 확인
- 모델 등록하기

#### run에서 모델 다운로드하기
```bash
uv run scripts/download_model_from_run.py 318bc2c545ee46618f236fe83de830b3 "weights/best_model" --download_dir "artifacts/runs"
```

#### 모델 등록하기
- 다운로드된 경로 확인
```bash
uv run scripts/register_yolo_model.py "yolo_test_model" "artifacts/runs/318bc2c545ee46618f236fe83de830b3/best_model/best.pt"
```
---

# 8. 모델 배포하기
- ONNX 변환 → 성능/정합성 확인
  1. .onnx로 변환
  2. .pt 모델과 .onnx 모델이 같은지 검증
  3. .onnx 모델 저장
- .pt vs .onnx 벤치마크
- 모델 등록하기

#### ONNX 변환 → 성능/정합성 확인
```bash
uv run scripts/convert_pt_to_onnx.py main "artifacts/yolo/yolo26n.pt" --output-dir "artifacts/yolo" --sample-dir "data/sample_data"
```
---

# 8. 모델 배포하기
#### .pt vs .onnx 벤치마크
```bash
uv run scripts/benchmark_models.py "artifacts/yolo/yolo26n.pt" "artifacts/yolo/yolo26n.onnx" "data/PCB_DATASET/images/Missing_hole"
```

#### 모델 등록하기
```bash
uv run scripts/register_yolo_onnx_model.py "yolo_pretrained_onnx" "artifacts/yolo/yolo26n.onnx"
```
---
# ml-object-detector 패키지로 예측하기
- 스크립트 실행
- 노트북 실행

### 스크립트 실행
```bash
uv run examples/ml_object_detector_demo.py
```
### 노트북 실행
`examples/ml_object_detector_demo.ipynb`

---

# Streamlit 앱에서 내 모델 확인하기
- ml-object-detector 패키지를 앱에 배포
- 데모 UI 기준으로 확인

```bash
streamlit run apps/object_detection_demo/main.py
```
